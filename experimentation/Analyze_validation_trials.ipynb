{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.stats.distributions\n",
    "from scipy.spatial.transform import Rotation\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import cvxpy as cp\n",
    "import csv\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/Gaze_project')\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EyeIK')\n",
    "from InputStructures import *\n",
    "from EyeCatch_implementation import *\n",
    "from Ground_truth_implementation import *\n",
    "from Oyekoya_implementation import *\n",
    "from Andrist_implementation import *\n",
    "from Goude_implementation import *\n",
    "from Jin_implementation import *\n",
    "from Itti_implementation import *\n",
    "from Pejsa_implementation import *\n",
    "import networkx as nx\n",
    "from Proposed_model import *\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport EyeCatch_implementation\n",
    "%aimport Oyekoya_implementation\n",
    "%aimport Andrist_implementation\n",
    "%aimport Goude_implementation\n",
    "%aimport Ground_truth_implementation\n",
    "%aimport Proposed_model\n",
    "%aimport Jin_implementation\n",
    "%aimport Itti_implementation\n",
    "%aimport Pejsa_implementation\n",
    "%aimport InputStructures\n",
    "%aimport Speech_Data_util\n",
    "%aimport Signal_processing_utils\n",
    "%aimport Geometry_Util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_motion(hk, ek, micro_saccade, outpath):\n",
    "    blend_weight = []\n",
    "    for i in range(1, len(hk[0])-1):\n",
    "        velocity = math.sqrt((hk[0][i][1]-hk[0][i-1][1])**2 + (hk[0][i-1][2]-hk[0][i][2])**2)\n",
    "        blend_weight.append([hk[0][i][0], 1 - min(1, velocity/0.75)])\n",
    "    out = {\"eye_frames\": ek,\n",
    "            \"head_frames\": hk,\n",
    "            \"micro_saccade\": micro_saccade,\n",
    "            \"other_neck\": [],\n",
    "            \"envelope\":[], \n",
    "            \"ambient_neck\":[]}\n",
    "            # \"output_times\": output_times, \n",
    "            # \"output_targets\": output_targets\n",
    "    with open(outpath, 'wb') as f:\n",
    "        pickle.dump(out, f, protocol=2)\n",
    "    print(outpath)\n",
    "class InternalModelFromCapture:\n",
    "    def __init__(self, input_json, gaze_arr = None):\n",
    "        # input json is generated from the quest pro capture from experimentation/Analyze_trajectory_research_paper.py\\\n",
    "        self.input_json = input_json\n",
    "        self.gaze_arr = gaze_arr\n",
    "    def estimate_target_pose(self, index):\n",
    "        if self.gaze_arr is not None:\n",
    "            angle = self.gaze_arr[index]\n",
    "        else:\n",
    "            angle = self.input_json[\"input_target_angle\"][index]\n",
    "        pos = directions_from_rotation_angles(np.array([[angle, 0]]), 100)[0]\n",
    "        return pos\n",
    "    def get_base_pose(self):\n",
    "        return np.array([0, 0, 100])\n",
    "def compare_kf_plot_hk(ek1, ek2, hk1, hk2, name1=\"GT\", name2=\"Proposed\", end = None):\n",
    "    # index 0 = time\n",
    "    # index 1 = sideways\n",
    "    hk1 = np.array(hk1)[0]\n",
    "    hk2 = np.array(hk2)[0]\n",
    "    if end is not None:\n",
    "        hk1 = hk1[:end]\n",
    "    # plt.plot(ek2[:, 0], ek2[:, 1], 'r')\n",
    "    if name1 == \"GT\":\n",
    "        hk1[:, 0] = hk1[:, 0] - 0.1\n",
    "        # find the largest time stamp in hk2 that is less than the final time stamp in hk1\n",
    "        hk2_interp = interp1d(hk2[:, 0], hk2[:, 1], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
    "        hk2_val = hk2_interp(hk1[:, 0])\n",
    "    else:\n",
    "        hk2 = hk2[:end]\n",
    "    plt.plot(hk1[:, 0], hk2_val, 'b', label=name2)\n",
    "    plt.plot(hk1[:, 0], hk1[:, 1], 'g', label=name1)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Neck angle (deg)\")\n",
    "\n",
    "    plt.show()  \n",
    "def compare_kf_plot_ek(ek1, ek2, hk1, hk2, name1=\"GT\", name2=\"Proposed\", end = None):\n",
    "    ek1 = np.array(ek1)[0]\n",
    "    ek2 = np.array(ek2)[0]\n",
    "    hk1 = np.array(hk1)[0]\n",
    "    hk2 = np.array(hk2)[0]\n",
    "    if end is not None:\n",
    "        hk1 = hk1[:end]\n",
    "        hk2 = hk2[:end]\n",
    "        ek1 = ek1[:end]\n",
    "        ek2 = ek2[:end]\n",
    "    ek_angles1 = rotation_angles_frome_positions(ek1[:, 1:])\n",
    "    ek_angles2 = rotation_angles_frome_positions(ek2[:, 1:])\n",
    "    if name1 == \"GT\":\n",
    "        hk1[:, 0] = hk1[:, 0] - 0.1\n",
    "        ek_angles2_interp = interp1d(ek2[:, 0], ek_angles2[:, 0], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
    "        ek_angles2_val = ek_angles2_interp(hk1[:, 0])\n",
    "    plt.plot(hk1[:, 0], ek_angles1[:, 0] + hk1[:, 1], 'g', label=name1)\n",
    "    plt.plot(hk1[:, 0], ek_angles2_val, 'b', label=name2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Eye angle (deg)\")\n",
    "    plt.show()  \n",
    "    \n",
    "def compare_kf_error_hk(ek1, ek2, hk1, hk2, name1=\"GT\"):\n",
    "    hk1 = np.array(hk1)[0]\n",
    "    hk2 = np.array(hk2)[0]\n",
    "    if name1 == \"GT\":\n",
    "        hk1[:, 0] = hk1[:, 0]\n",
    "    # resample the second one to be the same length as the first\n",
    "    hk2_interp = interp1d(hk2[:, 0], hk2[:, 1], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
    "    re_factor_hk2 = 1.0 * hk2_interp(hk1[:, 0])\n",
    "    mse = np.mean((hk1[:, 1] - re_factor_hk2)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIspersion filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_filtering(x, y, dispersion_threshold = 6, duraiton_threshold=0.2):\n",
    "    start = 0\n",
    "    window = []\n",
    "    if len(x) == 0:\n",
    "        return [], []\n",
    "    fps = int(np.round(1/(x[1] - x[0])))\n",
    "    duration_threshold_frames = np.ceil(duraiton_threshold * fps)\n",
    "    \n",
    "    def dispersion(arr):\n",
    "        # input is a 2d array\n",
    "        disp = np.max(arr[:, 0]) - np.min(arr[:, 0]) + np.max(arr[:, 1]) - np.min(arr[:, 1])\n",
    "        return disp\n",
    "\n",
    "    fixations = []\n",
    "    fixations_intervals = []\n",
    "    \n",
    "    # while there are still points\n",
    "    while int(start+duration_threshold_frames) < y.shape[0]:\n",
    "        # initialize a window:\n",
    "        window = list(range(int(start), int(start+duration_threshold_frames)))\n",
    "        start = start + duration_threshold_frames\n",
    "        disp = dispersion(y[window])\n",
    "        # while the dispersion is less than the threshold\n",
    "        while disp <= dispersion_threshold:\n",
    "            if window[-1]+1 < y.shape[0]:\n",
    "                window.append(window[-1]+1)\n",
    "            start = start + 1\n",
    "            if start >= y.shape[0]:\n",
    "                break\n",
    "            disp = dispersion(y[window])\n",
    "\n",
    "        # if the current set of points never fit the duration criteria\n",
    "        if len(window) <= duration_threshold_frames:\n",
    "            start = start + 1\n",
    "        # otherwise note it as fixations\n",
    "        else:\n",
    "            centroid = np.mean(y[window], axis=0)\n",
    "            duration = (window[-1] - window[0]) / fps\n",
    "            fixations.append([centroid[0], centroid[1], duration])\n",
    "            fixations_intervals.append([window[0], window[-1]])\n",
    "    fixations = np.array(fixations)\n",
    "    return fixations, fixations_intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Head Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_angles(head_dir, target_dir, target_fixations_intervals, target_fixation_duration, persistant_target_angle = 0):\n",
    "    # find the head fixations that are within the target fixations\n",
    "    head_fixation_final_val = []\n",
    "    head_fixations_closest_val = []\n",
    "    head_fixations_extreme_val = [] # not being used\n",
    "    head_fixations_value_held = [] # not being used \n",
    "    head_fixations_value_held_isValid = [] # not being used\n",
    "    # find a few head fixations that are within the target fixations\n",
    "    non_zero_fixation_angles = []\n",
    "    non_zero_fixation_duration = []\n",
    "    # find a few head fixations that are within the target fixations\n",
    "    for i in range(0, len(target_fixations_intervals)):\n",
    "        angle = target_dir[target_fixations_intervals[i][0]:target_fixations_intervals[i][1], 2].mean()\n",
    "        if np.abs(angle - persistant_target_angle) > 0:\n",
    "            non_zero_fixation_angles.append(angle) # this only record non-zero angles\n",
    "            non_zero_fixation_duration.append(target_fixation_duration[i])\n",
    "            target_interval = target_fixations_intervals[i]\n",
    "            start = target_interval[0]\n",
    "            end = target_interval[1]\n",
    "            ################# find the head intervals that starts within the target interval, and use average as angle of the head #################\n",
    "            # intersected = []\n",
    "            # for j in range(0, len(head_fixations_intervals)):\n",
    "            #     if head_fixations_intervals[j][0] >= start and head_fixations_intervals[j][0] <= end:\n",
    "            #         intersected.append(j)\n",
    "            # # the fixation interval closest to the target interval is selected\n",
    "            # closest_angle = 10000000\n",
    "            # closest_index = -100\n",
    "            # if len(intersected) > 0:\n",
    "            #     for j in intersected:\n",
    "            #         head_fixation_value = head_dir[head_fixations_intervals[j][0]:head_fixations_intervals[j][1]][:, 2].mean()\n",
    "            #         target_angle = target_dir[target_fixations_intervals[i][0]:target_fixations_intervals[i][1]][:, 2].mean()\n",
    "            #         if np.abs(head_fixation_value - target_angle) < closest_angle:\n",
    "            #             closest_angle = np.abs(head_fixation_value - target_angle)\n",
    "            #             closest_index = j\n",
    "            #     head_fixations_value_held.append(head_dir[head_fixations_intervals[closest_index][0]:head_fixations_intervals[closest_index][1]][:, 2].mean())\n",
    "            #     head_fixations_value_held_isValid.append(True)\n",
    "            # else:\n",
    "            #     head_fixations_value_held.append(head_dir[target_fixations_intervals[i][0]:target_fixations_intervals[i][1]][:, 2].mean())\n",
    "            #     head_fixations_value_held_isValid.append(False)\n",
    "            \n",
    "            ################# find the closest value within the target interval #################\n",
    "            extreme_value_index = np.argmin(np.abs(head_dir[start:end][:, 2] - angle))\n",
    "            head_fixations_closest_val.append(head_dir[start:end][:, 2][extreme_value_index])\n",
    "            # if head_fixations_closest_val[-1] / target_dir[start:end][:, 2].mean() < 0:\n",
    "            #     print(\"wrong sign\")\n",
    "            #     continue\n",
    "\n",
    "            ################# find the extreme value within the target interval #################\n",
    "            extreme_value_index = np.argmax(np.abs(head_dir[start:end][:, 2]))\n",
    "            head_fixations_extreme_val.append(head_dir[start:end][:, 2][extreme_value_index])\n",
    "\n",
    "            ################# find the final value within target interval #################\n",
    "            head_fixation_final_val.append(head_dir[end][2])\n",
    "            # plt.plot(head_dir[start:end][:, 0], head_dir[start:end][:, 2], label=\"head\")\n",
    "            # plt.plot(target_dir[start:end][:, 0], target_dir[start:end][:, 2], label=\"target\")\n",
    "            # plt.plot(head_dir[start:end][:, 0], np.ones(head_dir[start:end][:, 0].shape) * head_fixations_extreme_val[-1], label=\"head fixation (from extreme value method)\")\n",
    "            # plt.plot(head_dir[start:end][:, 0], np.ones(head_dir[start:end][:, 0].shape) * head_fixations_value_held[-1], label=\"head fixation (from value held method)\")\n",
    "            # plt.plot(head_dir[start:end][:, 0], np.ones(head_dir[start:end][:, 0].shape) * head_fixations_closest_val[-1], label=\"head fixation (from closest value method)\")\n",
    "            # plt.plot(head_dir[start:end][:, 0], np.ones(head_dir[start:end][:, 0].shape) * head_fixation_final_val[-1], label=\"head fixation (from final value method)\")\n",
    "          \n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "        else:\n",
    "            head_fixations_closest_val.append(persistant_target_angle)\n",
    "            head_fixations_extreme_val.append(persistant_target_angle)\n",
    "            head_fixations_value_held.append(persistant_target_angle)\n",
    "            head_fixations_value_held_isValid.append(False)\n",
    "            non_zero_fixation_angles.append(persistant_target_angle)\n",
    "            non_zero_fixation_duration.append(persistant_target_angle)\n",
    "    \n",
    "    head_fixations_closest_val = np.array(head_fixations_closest_val)\n",
    "    head_fixations_extreme_val = np.array(head_fixations_extreme_val)\n",
    "    head_fixations_value_held = np.array(head_fixations_value_held)\n",
    "    head_fixations_value_held_isValid = np.array(head_fixations_value_held_isValid)\n",
    "    head_fixation_final_val = np.array(head_fixation_final_val)\n",
    "    non_zero_fixation_angles = np.array(non_zero_fixation_angles)\n",
    "    non_zero_fixation_duration = np.array(non_zero_fixation_duration)\n",
    "    \n",
    "    return head_fixations_closest_val, non_zero_fixation_angles, non_zero_fixation_duration\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find CHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianKernal:\n",
    "    def __init__(self, loc, sigma, amplitude):\n",
    "        self.sigma = sigma\n",
    "        self.loc = loc\n",
    "        self.amplitude = amplitude\n",
    "        self.gaussina = scipy.stats.distributions.norm(loc, sigma)\n",
    "    def cumulate(self, t_arr, x_arr):\n",
    "        # t_arr is the time array\n",
    "        # x_arr is the value array, in which we will cumulate a series of GaussianKernals\n",
    "        x_arr += self.amplitude * self.gaussina.pdf(t_arr)\n",
    "        return x_arr\n",
    "\n",
    "def generate_smooth_distribution(fixation_angles):\n",
    "    # generate a smooth distribution of the fixation ang\n",
    "    kernal_list = []\n",
    "    kernal_std = 3\n",
    "    kernal_amplitude = 1\n",
    "    for i in range(len(fixation_angles)):\n",
    "        kernal_list.append(GaussianKernal(fixation_angles[i], kernal_std, kernal_amplitude))\n",
    "    t_arr = np.linspace(-100, 100, 1000)\n",
    "    x_arr = np.zeros(t_arr.shape)\n",
    "    for kernal in kernal_list:\n",
    "        x_arr = kernal.cumulate(t_arr, x_arr)\n",
    "    x_arr = x_arr/np.sum(x_arr)\n",
    "    return t_arr, x_arr, kernal_list\n",
    "def generate_CHOR_distribution(head_angles, target_angles, target_angle_distribution):\n",
    "    # find the closest angle in the target angle distribution for each head angle\n",
    "    head_kernal_list = []\n",
    "    for i in range(len(target_angles)):\n",
    "        closest_target_angle_index = np.argmin(np.abs(target_angle_distribution[0] - target_angles[i]))\n",
    "        # scaling the amplitude of each head angle by the corresponding target angle distribution\n",
    "        head_kernal_list.append(GaussianKernal(head_angles[i], 3, 1 / target_angle_distribution[1][closest_target_angle_index]))\n",
    "    t_arr = np.linspace(-100, 100, 1000)\n",
    "    x_arr = np.zeros(t_arr.shape)\n",
    "    for kernal in head_kernal_list:\n",
    "        x_arr = kernal.cumulate(t_arr, x_arr)\n",
    "    x_arr = x_arr/np.sum(x_arr)\n",
    "    # find start and end range that contains 90% of the distribution\n",
    "    cumulative_x_arr = np.cumsum(x_arr)\n",
    "    start_index = np.argmin(np.abs(cumulative_x_arr - 0.05))\n",
    "    end_index = np.argmin(np.abs(cumulative_x_arr - 0.95))\n",
    "    start_angle = t_arr[start_index]\n",
    "    end_angle = t_arr[end_index]\n",
    "\n",
    "    return t_arr, x_arr, start_angle, end_angle\n",
    "def get_CHOR(fixation_angles, head_fixation_angles, angle_to_ignore=0):\n",
    "    is_not_zero = np.where(np.abs(fixation_angles-angle_to_ignore) <= 1E-3, False, True)\n",
    "    target_angle_distribution = generate_smooth_distribution(fixation_angles[is_not_zero])\n",
    "    head_angle_distribution = generate_CHOR_distribution(head_fixation_angles[is_not_zero], fixation_angles[is_not_zero], target_angle_distribution)\n",
    "    CHOR_start, CHOR_end = head_angle_distribution[2], head_angle_distribution[3]\n",
    "    return CHOR_start, CHOR_end, target_angle_distribution, head_angle_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_target_and_results(collected_gaze, collected_duration, target_gaze, target_duration):\n",
    "    deletion_index = -1\n",
    "    for i in range(0, len(target_duration)):\n",
    "        if np.abs(collected_gaze[i] - target_gaze[i]) > 1E-3:\n",
    "            deletion_index = i\n",
    "            break\n",
    "\n",
    "    if deletion_index < 0:\n",
    "        return target_gaze, target_duration\n",
    "    else:\n",
    "        new_target_gaze = np.concatenate([target_gaze[0:deletion_index], target_gaze[deletion_index+1:]])\n",
    "        new_target_duration = np.concatenate([target_duration[0:deletion_index], target_duration[deletion_index+1:]])\n",
    "        return new_target_gaze, new_target_duration\n",
    "    \n",
    "def get_gaze_inputs_naive(eye_traj, head_traj, input_times, input_angles):\n",
    "    gaze_traj = eye_traj[:, 1:] + head_traj[:, 1:]\n",
    "    gaze_fixations, gaze_fixations_intervals = dispersion_filtering(eye_traj[:, 0], gaze_traj[:, 1:], 3, duraiton_threshold=0.05)\n",
    "    # gaze_fixations_angles = gaze_fixations[:, 1]\n",
    "    # gaze_fixation_duration = gaze_fixations[:, 2]\n",
    "    # time arr\n",
    "    ts = eye_traj[:, 0]\n",
    "    ts = ts - ts[0]\n",
    "    input_sequence = []\n",
    "    for i in range(0, len(gaze_fixations)):\n",
    "        input_sequence.append([ts[gaze_fixations_intervals[i][0]], gaze_fixations[i, 0]])\n",
    "    input_sequence = np.array(input_sequence).T\n",
    "    return input_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_target_and_results(collected_gaze, collected_duration, target_gaze, target_duration):\n",
    "    deletion_index = -1\n",
    "    for i in range(0, len(target_duration)):\n",
    "        if np.abs(collected_gaze[i] - target_gaze[i]) > 1E-3:\n",
    "            deletion_index = i\n",
    "            break\n",
    "\n",
    "    if deletion_index < 0:\n",
    "        return target_gaze, target_duration\n",
    "    else:\n",
    "        new_target_gaze = np.concatenate([target_gaze[0:deletion_index], target_gaze[deletion_index+1:]])\n",
    "        new_target_duration = np.concatenate([target_duration[0:deletion_index], target_duration[deletion_index+1:]])\n",
    "        return new_target_gaze, new_target_duration\n",
    "def get_angle_per_instance(head_dir, eye_dir, target_pos, target_input, three_target=False):\n",
    "        # prevent the angle from going to 360\n",
    "    head_dir[:, 1:] = np.where(head_dir[:, 1:] > 180, head_dir[:, 1:] - 360, head_dir[:, 1:]) \n",
    "    eye_dir[:, 1:] = np.where(eye_dir[:, 1:] > 180, eye_dir[:, 1:] - 360, eye_dir[:, 1:])     \n",
    "    \n",
    "    # get the target directions\n",
    "    target_dir = np.zeros(target_pos.shape)\n",
    "    target_dir[:, 0] = target_pos[:, 0]\n",
    "    for i in range(target_pos.shape[0]):\n",
    "        # get the object rotation from scipy\n",
    "        vec = target_pos[i, 1:]\n",
    "        vec = vec / np.linalg.norm(vec)\n",
    "        rot_y = np.sign(vec[0]) * (90 - np.arctan(abs(vec[2])/abs(vec[0])) * 180 / np.pi)\n",
    "        # print(rot_y, target_dir[i, 2])\n",
    "        target_dir[i, 2] = -rot_y\n",
    "    # plt.plot(target_dir[:, 2].tolist())\n",
    "    # note the dispersion is originally for a 2D input array\n",
    "    target_fixations, target_fixations_intervals = dispersion_filtering(target_dir[:, 0], target_dir[:, 1:], 0.1, duraiton_threshold=0.0001)\n",
    "    # find the number of nans in target_dir\n",
    "    target_fixations_angles = target_fixations[:, 1]\n",
    "    target_fixation_duration = target_fixations[:, 2]\n",
    "    # get the combined head and eye angles\n",
    "    gaze_dir = eye_dir + head_dir\n",
    "    gaze_fixations, gaze_fixations_intervals = dispersion_filtering(gaze_dir[:, 0], gaze_dir[:, 1:], 3, duraiton_threshold=0.2)\n",
    "    gaze_fixations_angles = gaze_fixations[:, 1]\n",
    "    gaze_fixation_duration = gaze_fixations[:, 2]\n",
    "\n",
    "\n",
    "    # get the target durations from the experimental setup file\n",
    "    target_present_duration = target_input[\"duration\"]\n",
    "    # valid_target_list = np.array(target_input[\"isTarget\"])\n",
    "    # valid_target_list = np.where(valid_target_list==1, True, False)\n",
    "    target_present_duration = np.array(target_present_duration)\n",
    "    # target_present_duration = target_present_duration[valid_target_list]\n",
    "    target_fixation_angles = target_input[\"angle\"]\n",
    "    target_fixation_angles = np.array(target_fixation_angles)\n",
    "    # target_fixation_angles = target_fixation_angles[valid_target_list]\n",
    "    head_fixation_angles, fixation_angles, fixation_duration = get_head_angles(head_dir, target_dir, target_fixations_intervals, target_fixation_duration, persistant_target_angle=0)\n",
    "    # remove all the zero angles of collected data\n",
    "    fixation_angles = np.array(fixation_angles)\n",
    "    fixation_duration = np.array(fixation_duration)\n",
    "    head_fixation_angles = np.array(head_fixation_angles)\n",
    "    target_fixation_angles, target_present_duration = align_target_and_results(fixation_angles, fixation_duration, target_fixation_angles, target_present_duration)\n",
    "    \n",
    "    if three_target:\n",
    "        # make sure the structure nice\n",
    "        added_index = []\n",
    "        minus_index = []\n",
    "        off_set = 0\n",
    "        for i in range(0, int(len(target_fixation_angles)/3)):\n",
    "            if target_fixation_angles[3*i+1+off_set] in set([20, -40]):\n",
    "                continue\n",
    "            else:\n",
    "                if target_fixation_angles[np.minimum(3*i+off_set, len(target_fixation_angles)-1)] in set([20, -40]):\n",
    "                    added_index.append(3*i)\n",
    "                    off_set += 1\n",
    "                elif target_fixation_angles[np.minimum(3*i+2+off_set, len(target_fixation_angles)-1)] in set([20, -40]):\n",
    "                    minus_index.append(3*i+2)\n",
    "            \n",
    "        target_fixation_angles = np.insert(target_fixation_angles, added_index, 0, axis=0)\n",
    "        target_present_duration = np.insert(target_present_duration, added_index, 1, axis=0)\n",
    "        head_fixation_angles = np.insert(head_fixation_angles, added_index, 0, axis=0)\n",
    "        fixation_angles = np.insert(fixation_angles, added_index, 0, axis=0)        \n",
    "    return target_fixation_angles, target_fixation_duration, fixation_angles, head_fixation_angles, target_present_duration\n",
    "\n",
    "def get_interval_per_instance(head_dir, eye_dir, target_pos, target_input, three_target=False):\n",
    "    head_dir[:, 1:] = np.where(head_dir[:, 1:] > 180, head_dir[:, 1:] - 360, head_dir[:, 1:]) \n",
    "    eye_dir[:, 1:] = np.where(eye_dir[:, 1:] > 180, eye_dir[:, 1:] - 360, eye_dir[:, 1:])     \n",
    "    \n",
    "    # get the target directions\n",
    "    target_dir = np.zeros(target_pos.shape)\n",
    "    target_dir[:, 0] = target_pos[:, 0]\n",
    "    for i in range(target_pos.shape[0]):\n",
    "        # get the object rotation from scipy\n",
    "        vec = target_pos[i, 1:]\n",
    "        vec = vec / np.linalg.norm(vec)\n",
    "        rot_y = np.sign(vec[0]) * (90 - np.arctan(abs(vec[2])/abs(vec[0])) * 180 / np.pi)\n",
    "        # print(rot_y, target_dir[i, 2])\n",
    "        target_dir[i, 2] = -rot_y\n",
    "\n",
    "    # note the dispersion is originally for a 2D input array\n",
    "    target_fixations, target_fixations_intervals = dispersion_filtering(target_dir[:, 0], target_dir[:, 1:], 0)\n",
    "    target_fixations_angles = target_fixations[:, 1]\n",
    "    target_fixation_duration = target_fixations[:, 2]\n",
    "    target_fixation_angles = target_input[\"angle\"]\n",
    "    target_fixation_angles = np.array(target_fixation_angles)\n",
    "    target_present_duration = target_input[\"duration\"]\n",
    "\n",
    "    head_fixation_angles, fixation_angles, fixation_duration = get_head_angles(head_dir, target_dir, target_fixations_intervals, target_fixation_duration, persistant_target_angle=0)\n",
    "    \n",
    "    # remove all the zero angles of collected data\n",
    "    fixation_angles = np.array(fixation_angles)\n",
    "    fixation_duration = np.array(fixation_duration)\n",
    "    head_fixation_angles = np.array(head_fixation_angles)\n",
    "    \n",
    "    \n",
    "    target_fixation_angles, target_present_duration = align_target_and_results(fixation_angles, fixation_duration, target_fixation_angles, target_present_duration)\n",
    "\n",
    "\n",
    "    if three_target:\n",
    "        # make sure the structure is nice\n",
    "        added_index = []\n",
    "        minus_index = []\n",
    "        off_set = 0\n",
    "        for i in range(0, int(len(target_fixation_angles)/3)):\n",
    "            if target_fixation_angles[3*i+1+off_set] in set([20, -40]):\n",
    "                continue\n",
    "            else:\n",
    "                if target_fixation_angles[np.minimum(3*i+off_set, len(target_fixation_angles)-1)] in set([20, -40]):\n",
    "                    added_index.append(3*i)\n",
    "                    off_set += 1\n",
    "                elif target_fixation_angles[np.minimum(3*i+2+off_set, len(target_fixation_angles)-1)] in set([20, -40]):\n",
    "                    minus_index.append(3*i+2)\n",
    "        for i in range(0, len(added_index)):\n",
    "            list.insert(target_fixations_intervals, added_index[len(added_index)-1-i], [0, 0])\n",
    "        return target_fixations_intervals\n",
    "    else:\n",
    "        return target_fixations_intervals\n",
    "\n",
    "# target_fixation_intervals = get_interval_per_instance(all_head_data[0], all_eye_data[0], all_target_data[0], all_target_input[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_from_txt_aug(full_path):\n",
    "    with open(full_path, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        rows = [row for row in reader]\n",
    "    # Process rows to ensure they all have 4 elements\n",
    "    filtered_rows = []\n",
    "    for row in rows:\n",
    "        # remove spaces \n",
    "        row_no_space = []\n",
    "        for i in range(0, len(row)):\n",
    "            if row[i] != \"\" and row[i] != \" \":\n",
    "                row_no_space.append(row[i])\n",
    "        while len(row_no_space) < 4:\n",
    "            row_no_space.append(np.nan)  # Append NaN for missing values\n",
    "        filtered_rows.append(row_no_space)\n",
    "    # Convert to NumPy array\n",
    "    data = np.array(filtered_rows, dtype=float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/evanpan/Desktop/collected_data_VR\"\n",
    "input_dirs = []\n",
    "users = os.listdir(input_dir)\n",
    "for i in range(len(users)):\n",
    "    if users[i].startswith(\"user\"):\n",
    "        input_dirs.append(os.path.join(input_dir, users[i]))\n",
    "all_trials = []\n",
    "recording_file_names = [\"random_condition\", \"wackamole\", \"see_through_task\"]\n",
    "for input_dir in input_dirs:\n",
    "    # to store the trials of a single subject\n",
    "    trial_per_subject = {}\n",
    "    dirs = os.listdir(input_dir)\n",
    "    # get duration of each trial:\n",
    "    total_length = 0\n",
    "    data_types = [\"gaze_dir\", \"head_dir\", \"head_pos\", \"target_pos\"]\n",
    "    for fileName in recording_file_names:\n",
    "        all_eye_data = []\n",
    "        all_head_data = []\n",
    "        all_target_data = []\n",
    "        all_target_input = []\n",
    "\n",
    "        data_type = \"gaze_dir\"\n",
    "        fullPath = os.path.join(input_dir, data_type + \"_\" + fileName + \".csv\")\n",
    "        eye_data = np_from_txt_aug(fullPath)\n",
    "        data_type = \"head_dir\"\n",
    "        fullPath = os.path.join(input_dir, data_type + \"_\" + fileName + \".csv\")\n",
    "        head_data = np_from_txt_aug(fullPath)\n",
    "        \n",
    "        if fileName == \"random_condition\":\n",
    "            setupFileName = os.path.join(*[input_dir, fileName+\".json\"])\n",
    "            data_type = \"target_pos\"\n",
    "            fullPath = os.path.join(input_dir, data_type + \"_\" + fileName + \".csv\")\n",
    "            target_data = np_from_txt_aug(fullPath)\n",
    "            all_target_data.append(target_data)\n",
    "            trial_per_subject[fileName] = [all_eye_data, all_head_data, all_target_data, all_target_input]\n",
    "            target_input = json.load(open(setupFileName, \"r\"))\n",
    "            all_target_input.append(target_input)\n",
    "        all_eye_data.append(eye_data)\n",
    "        all_head_data.append(head_data)\n",
    "        \n",
    "        trial_per_subject[fileName] = [all_eye_data, all_head_data]\n",
    "    all_trials.append(trial_per_subject)\n",
    "\n",
    "# parse the data (the wackamole data has some corrupted timestamps (the recording doesn't properly stop after the user take off the headset))\n",
    "recording_file_names = [\"random_condition\", \"wackamole\", \"see_through_task\"]\n",
    "# recording_file_names = [\"wackamole\"]\n",
    "for i in range(0, len(all_trials)):\n",
    "    for j in recording_file_names:\n",
    "        subject_i_type_j_data = all_trials[i][j][0][0]\n",
    "        # the timing is screwed past certain index, must filter it out\n",
    "        bad_apple = -1\n",
    "        for t in range(0, subject_i_type_j_data.shape[0]):\n",
    "            if subject_i_type_j_data[t, 0] - subject_i_type_j_data[t-1, 0] > 0.1:\n",
    "                bad_apple = t\n",
    "                break\n",
    "        if bad_apple > 0:\n",
    "            subject_i_type_j_data = subject_i_type_j_data[0:bad_apple-1]\n",
    "        all_trials[i][j][0][0] = subject_i_type_j_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total length of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length (minutes):  82.549455315\n",
      "total frames:  355894\n",
      "average length (minutes):  1.8344323403333334\n",
      "average frames:  7908.7555555555555\n"
     ]
    }
   ],
   "source": [
    "total_length = 0 \n",
    "total_clip_count = 0\n",
    "total_frames = 0\n",
    "recording_file_names = [\"random_condition\", \"wackamole\", \"see_through_task\"]\n",
    "# recording_file_names = [\"wackamole\"]\n",
    "for i in range(0, len(all_trials)):\n",
    "    for j in recording_file_names:\n",
    "        # get the data\n",
    "        subject_i_type_j_data = all_trials[i][j][0][0]\n",
    "        total_length += subject_i_type_j_data[-1, 0] - subject_i_type_j_data[0, 0]\n",
    "        total_frames += subject_i_type_j_data.shape[0]\n",
    "        total_clip_count += 1\n",
    "print(\"total length (minutes): \", total_length/60)\n",
    "print(\"total frames: \", total_frames)\n",
    "print(\"average length (minutes): \", total_length/total_clip_count/60)\n",
    "print(\"average frames: \", total_frames/total_clip_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate existing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from Proposed_model import *\n",
    "def dwell_factored_eye_strain_function(dwell_time, angle_j, angle0, angle1):\n",
    "    # vanilla\n",
    "    # dwell_time_factor1 = dwell_time\n",
    "    # dwell_time_factor0 = np.maximum(1.5 - dwell_time, 0)\n",
    "    # probably better?\n",
    "    dwell_time_factor1 = np.maximum(0.0001, 1 - np.exp(-0.8*dwell_time)) # this is higher for shorter dwell times)\n",
    "    dwell_time_factor0 = np.exp(-0.8*dwell_time) # this is higher for longer dwell times\n",
    "    return dwell_time_factor0 * np.linalg.norm(angle_j - angle1) + dwell_time_factor1 * np.linalg.norm(angle_j - angle0) + 0.4 *np.abs(angle_j)\n",
    "def head_moving_cost_function(prev, current, dwell_time, laziness=0.6):\n",
    "    # cost is the distance the the head has to move\n",
    "    cost = laziness * np.linalg.norm(prev - current)\n",
    "    if np.linalg.norm(prev - current) <= 4:\n",
    "        cost = 0\n",
    "    # but this cost is lowered in the direction of the midline\n",
    "    # return np.maximum(0.0001, 1.5-np.log(dwell_time + 1)) * cost\n",
    "    return np.exp(-0.8*dwell_time) * cost\n",
    "def create_graph(self, laziness=0.5):\n",
    "    gaze_trajectory_1 = self.input_gaze_pos_as_angles_per_frame\n",
    "    gaze_trajectory_0 = self.input_gaze_pos_as_angles_per_frame_smoothed\n",
    "    gaze_positions = self.gaze_pos_as_angles\n",
    "    gaze_intervals = self.target_gaze_intervals_time\n",
    "    graphs = []\n",
    "    for dimension in range(0, 2):\n",
    "        if dimension == 0:\n",
    "            range_limit = 60\n",
    "        else:\n",
    "            range_limit = 30\n",
    "        G = nx.DiGraph()\n",
    "        list_plot = []\n",
    "        for i in range(0, gaze_positions.shape[0]):\n",
    "            t_index = int(np.ceil(gaze_intervals[i][0]/self.simulation_dt))\n",
    "            t_index = min(t_index, gaze_trajectory_0.shape[0]-1)\n",
    "            target_angle_0 = gaze_trajectory_0[t_index, dimension]\n",
    "            target_angle_1 = gaze_trajectory_1[t_index, dimension]\n",
    "            list_plot.append(target_angle_1)\n",
    "            dwell_time = gaze_intervals[i][1] - gaze_intervals[i][0]\n",
    "            for j in range(-range_limit, range_limit, 2):\n",
    "                G.add_node((i, j), value=dwell_factored_eye_strain_function(dwell_time, j, target_angle_0, target_angle_1))\n",
    "                if i > 0:\n",
    "                    for j_prev in range(-range_limit, range_limit, 2):\n",
    "                        G.add_edge((i-1, j_prev), (i, j), weight=head_moving_cost_function(j_prev, j, dwell_time, laziness=laziness))\n",
    "        G.add_node((gaze_positions.shape[0], int(gaze_positions[-1][dimension])), value=0)\n",
    "        for j_prev in range(-range_limit, range_limit, 2):\n",
    "            G.add_edge((gaze_positions.shape[0]-1, j_prev), (gaze_positions.shape[0], int(gaze_positions[-1][dimension])), weight=head_moving_cost_function(j_prev, j, dwell_time))\n",
    "        graphs.append(G)\n",
    "    return graphs\n",
    "def optimize_head_pos(self, saccade_generator, laziness=0.54):\n",
    "    G_0, G_1 = create_graph(self, laziness)\n",
    "    def combined_weight0(u, v, d):\n",
    "        return G_0.nodes[v]['value'] + d['weight']\n",
    "    def combined_weight1(u, v, d):\n",
    "        return G_1.nodes[v]['value'] + d['weight']\n",
    "    path_0 = nx.dijkstra_path(G_0, (0, 0), (saccade_generator.gaze_pos_as_angles.shape[0], int(self.gaze_pos_as_angles[-1][0])), combined_weight0)\n",
    "    path_0 = np.array(path_0)[:, 1:2]\n",
    "    path_1 = nx.dijkstra_path(G_1, (0, 0), (saccade_generator.gaze_pos_as_angles.shape[0], int(self.gaze_pos_as_angles[-1][1])), combined_weight1)\n",
    "    path_1 = np.array(path_1)[:, 1:2]\n",
    "    head_angles = np.concatenate([path_0, path_1], axis=1)\n",
    "    head_pos = directions_from_rotation_angles(head_angles, 100)\n",
    "    return head_angles, head_pos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For controlled target-looking example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angle': [0.0, 40.0, 20.0, 60.0, 20.0, 60.0, 20.0, 60.0, 20.0, 60.0, 20.0, 60.0, 40.0, 20.0, 10.0, -10.0, 30.0, -10.0, 30.0, -10.0, 30.0, -10.0, 30.0, -10.0, 30.0, 10.0, 30.0, -30.0, -70.0, 10.0, -70.0, 10.0, -70.0, 10.0, -70.0, 10.0, -70.0, 10.0, -30.0, 60.0, -40.0, -60.0, -90.0, -40.0, -80.0, 0.0, -80.0, 0.0, -80.0, 0.0, -80.0, 0.0, -80.0, 0.0, -40.0, 30.0, -10.0, 70.0, -10.0, 70.0, -10.0, 70.0, -10.0, 70.0, -10.0, 70.0, 30.0], 'duration': [1.5, 1.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.5, 0.2, 1.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.5, 0.2, 1.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.5, 0.2, 0.2, 0.1, 1.5, 1.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.5, 1.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.5], 'isTarget': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'willReturnTo': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'showOnward': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_target_angle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_json_0)\n\u001b[1;32m     13\u001b[0m sequence_0 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43minput_json_0\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_target_angle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m     15\u001b[0m     sequence_0\u001b[38;5;241m.\u001b[39mappend([input_json_0[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_target_times\u001b[39m\u001b[38;5;124m\"\u001b[39m][i], input_json_0[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_target_angle\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]])\n\u001b[1;32m     16\u001b[0m input_json \u001b[38;5;241m=\u001b[39m input_json_0\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_target_angle'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "target_look_at_error_dict = {}\n",
    "\n",
    "fileName = \"random_condition\"\n",
    "for id_i in range(len(input_dirs)):\n",
    "    input_dir = input_dirs[id_i]\n",
    "    setupFileName = os.path.join(*[input_dir, fileName+\".json\"])\n",
    "    input_json_0 = json.load(open(setupFileName, \"r\"))\n",
    "    internal_model_0 = InternalModelFromCapture(input_json_0)\n",
    "    sequence_0 = []\n",
    "    for i in range(0, len(input_json_0[\"input_target_angle\"])):\n",
    "        sequence_0.append([input_json_0[\"input_target_times\"][i], input_json_0[\"input_target_angle\"][i]])\n",
    "    input_json = input_json_0\n",
    "    sequence = sequence_0\n",
    "    input_sequence = get_gaze_inputs_naive(np.array(input_json[\"eye_trajectory\"]), np.array(input_json[\"head_trajectory\"]), input_json[\"input_target_times\"], input_json[\"input_target_angle\"])\n",
    "    internal_model = InternalModelFromCapture(input_json, gaze_arr = input_sequence[1].copy())\n",
    "    for i in range(0, input_sequence.shape[1]):\n",
    "        input_sequence[1][i] = int(i)\n",
    "    gaze_positions = []\n",
    "    for i in range(0, input_sequence.shape[1]):\n",
    "        gaze_positions.append(internal_model.estimate_target_pose(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
